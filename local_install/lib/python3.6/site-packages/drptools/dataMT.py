
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import OrderedDict

from data import *



class DRPCatalogsMT(DRPLoader):

    def __init__(self, drp_path):
        """The 'drp_path' input is the path to the DRP output directory."""
        super().__init__(drp_path)

        # Initialize data dictionnaries
        self.nbMaxThread=25

    def load_catalogs(self, catalogs, **kwargs):
        """Load a list of catalogs.

        :param str/list catalogs: A catalog name, or a list of catalogs (see below)
        :param dict keys: A dictionnary of keys to load for each catalog

        Available kwargs are:

        :param bool update: Set to True if you want to update an already loaded catalog
        :param bool show: Set to True to get all available keys of a (list of) catalog(s)
        :param bool matchid: Will only keep objects which are in the deepCoad catalogs (to be used
                             when loading the forced_src and deepCoadd catalogs)

        Examples of catalogs that you can load:

         - 'deepCoadd_ref',
         - 'deepCoadd_meas',
         - 'deepCoadd_forced_src',
         - 'deepCoadd_calexp',
         - 'forced_src'
         - 'src'
        """
        if 'show' in kwargs:
            self.show_keys(catalogs)
            return
        keys = {} if 'keys' not in kwargs else kwargs['keys']
        catalogs = [catalogs] if isinstance(catalogs, str) else catalogs
        if any(["deepCoadd" in cat for cat in catalogs]):
            self._load_calexp(**kwargs)
        else:
            self._load_calexp(calcat='calexp', **kwargs)
        for catalog in sorted(catalogs):
            if catalog in self.catalogs and 'update' not in kwargs:
                print(colored("\nWARNING: %s is already loaded. Use 'update' to reload it." %
                              catalog, "yellow"))
                continue
            if 'calexp' in catalog:
                print(colored("\nWARNING: Skipping %s. Not a regular catalog (no schema).\n" %
                              catalog, "yellow"))
                continue
            print(colored("\nINFO: Loading the %s catalog" % catalog, 'green'))
            self.keys[catalog] = keys.get(catalog, "*")
            self._load_catalog(catalog, **kwargs)
        self._match_deepcoadd_catalogs()
        if 'output_name' in kwargs and self.from_butler['wcs'] is not None:
            self.save_catalogs(kwargs['output_name'],
                               'wcs', kwargs.get('overwrite', False))
        print(colored("\nINFO: Done loading the data.", "green"))

    
    def BrowseDataCatalog_Thread(args):

        dataType,vDict,paramList,paramTypeList=args

        tract_patch_data_id_2 = vDict

        f = drpLoader.butler.get(datasetType=dataType,dataId=tract_patch_data_id_2)

        try:
            hdul = fits.open(f[0])
            data = hdul[1].data

    #        paramList_new=[ x for x in paramList if x in data.names]
            paramList_new=paamList

            arr={}
            for p in paramList_new:
                arr[p]=data[p]

            threadData = Table(arr) #,dtypes=tuple(paramTypeList))

            del data
            hdul.close()

        except:
            threadData=Table()
            print("ERROR while opening file corresponding to : ",vDict)

        return threadData
    
        

    def BrowseDataCatalogs_MainThread(tableName,paramListInit,paramTypeDict,DMdataModel,uniqueKey):

        dataIdParam=['filter','tract','patch']

        paramIdList=[x for x in paramListInit if x in dataIdParam]
        paramList=[x for x in paramListInit if x not in dataIdParam]
        paramTypeList=[paramTypeDict[x].name for x in paramList]

        print("---- PARAM LIST -----------------------------------------------")
        print(tableName)
        print(paramList)
        print(paramTypeList)
        print("---------------------------------------------------------------")





        # data table based on filter,tract,patch only
        if len(paramList)==0:
            return BrowseDataCatalogs_DataIdsOnly(paramIdList)

        print("MAINTHREAD uniqueKey : ",uniqueKey)

        #Thread to read data from butler
        idTableName=tableName
        if "id_table" in DMdataModel.keys(): idTableName=DMdataModel["id_table"]
        nbIds=len(drpLoader.dataIds[idTableName])
        idsList=drpLoader.dataIds[idTableName]

        import random
        random.shuffle(idsList)

        nbMaxThread=25
        nbMaxIdPerPool=100

        stepPoolList=[(i,min(i+nbMaxIdPerPool,nbIds)) for i in range(0, nbIds, nbMaxIdPerPool)]
        print(stepPoolList)

        time0=time.time()

        icmpt_step=0
        finalTable=None
        nbEntries=0
        nbDiffEntries=0
        dataType=idTableName+"_filename"
        for step in stepPoolList:
            iFirst,iLast=step
            nbCatEntries=iLast-iFirst

            print()
            print("Step : ",iFirst," to ",iLast)

            icmpt=0
            runningThreads=[]
            with ThreadPoolExecutor(max_workers=nbMaxThread) as executor:
                for i,v in enumerate(idsList[iFirst:iLast]):
                    arg=(dataType,v,paramList,paramTypeList)
                    runningThreads.append(executor.submit(BrowseDataCatalog_Thread,arg))

                iCompletedThreads=0
                for threadOutput in as_completed(runningThreads):

                    iCompletedThreads+=1                
                    dataTable = threadOutput.result()

                    nbData=len(dataTable)
                    if nbData>0:

                        nbEntries+=nbData
                        if not finalTable:
                            finalTable=dataTable.copy()
                        else:

                            finalTable_tmp=vstack([finalTable,dataTable])                        
                            if uniqueKey:
                                finalTable=unique(finalTable_tmp,keys=uniqueKey)
                            else:
                                finalTable=finalTable_tmp

    ##                         diffTable=setdiff(dataTable,finalTable)
    ##                         nbDiffEntries+=len(diffTable)
    ##                         if len(diffTable)>0:
    ##                             finalTable_tmp=vstack([finalTable,diffTable])
    ##                             finalTable=finalTable_tmp


                    nbEntries_current=0
                    if finalTable: nbEntries_current=len(finalTable)
                    progress=int(icmpt*100./nbCatEntries)
                    sys.stdout.write("Download progress: %d%s   - %d/%d\r" % (progress,"%",nbEntries_current,nbEntries) )
                    sys.stdout.flush()
                    icmpt+=1
                    icmpt_step+=1

        time1=time.time()

        print()
        print('All tasks has been finished  ',len(finalTable))

        return finalTable




    
        
